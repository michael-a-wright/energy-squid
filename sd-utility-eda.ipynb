{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bitbasecondabf8fb41153a84f57a80aba5a735c6d6d",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layered Correlation Histogram\n",
    "### Used for: Classification tasks with quantitative features.\n",
    "\n",
    "This function takes a dataframe, a response variable (target), and an explanatory variable (predictor).\n",
    "It will then generate a histogram showing the distribution of the target variable grouped by the target variable,\n",
    "for the purposes of exploratory data analysis. Output graphs are stored in the visualizations/exploration/ folder\n",
    "of the project.\n",
    "\n",
    "**df**: Dataframe that will be processed.\n",
    "\n",
    "**target**: Response variable column.\n",
    "\n",
    "**predictor**: Explanatory variable column.\n",
    "\n",
    "**predictor/target_mask**: Optional names for predictor and response in chart labels. Default is to match\n",
    "  predictor and target column names exactly.\n",
    "\n",
    "**style**: PLT style to use. Defaults to default style.\n",
    "\n",
    "**dpi**: DPI of image to save. Default 160.\n",
    "\n",
    "**Fontsize**: Font of all text in the graph. Default 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrHist(df,predictor,target,predictor_mask='',target_mask='',style='default',dpi=160,fontsize=10):\n",
    "    if not predictor_mask:\n",
    "        predictor_mask = predictor\n",
    "    if not target_mask:\n",
    "        target_mask = target\n",
    "    plt.style.use(style)\n",
    "    df = df.dropna(subset=[predictor])\n",
    "    plt.figure(figsize=(10,8))\n",
    "    for i in df[target].unique():\n",
    "        plt.hist(df[df[target]==i][predictor],10,alpha=0.5,label=i)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel(predictor_mask)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of {} grouped by {}'.format(predictor_mask,target_mask))\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.savefig('visualizations/exploration/hist{}by{}.png'.format(predictor,target),dpi=dpi,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked Percentage Bar Chart\n",
    "### Used for: Classification tasks with quantitative and qualitative features.\n",
    "\n",
    "This function takes a dataframe, a response variable, and an explanatory variable.\n",
    "It will then generate a normalized stacked bar plot showing the percentage distribution of the target\n",
    "variable within the predictor variable for the purposes of exploratory data analysis.\n",
    "If the predictor is quantitative, this function will automatically separate it into ten bins before\n",
    "proceeding.\n",
    "\n",
    "Arguments:\n",
    "\n",
    "**df**: Dataframe that will be processed.\n",
    "\n",
    "**target**: Response variable column.\n",
    "\n",
    "**predictor**: Explanatory variable column.\n",
    "\n",
    "**predictor/target_mask**: Optional names for predictor and response in chart labels. Default is to match\n",
    "  predictor and target column names exactly.\n",
    "\n",
    "**predictor/target_values_mask**: Accepts a dictionary in the format:\n",
    "\n",
    "    {predictor/target: {value1: new_name1, value2: new_name2, ...}}\n",
    "\n",
    "  For example, in the Titanic dataset:\n",
    "  \n",
    "    {'Survived': {0: 'Perished', 1: 'Survived'}}\n",
    "\n",
    "**style**: PLT style to use. Defaults to default style.\n",
    "\n",
    "**verbose**: Adds number labels to bar slices. Default true.\n",
    "\n",
    "**dpi**: DPI of image to save. Default 160.\n",
    "\n",
    "**Fontsize**: Font of all text in the graph. Default 10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percBar(df,predictor,target,predictor_mask='',target_mask='',predictor_values_mask='',target_values_mask='',style='default',verbose=True,dpi=160,fontsize=10):\n",
    "    df = df.copy()\n",
    "    if(df[predictor].dtype!=object):\n",
    "        df[predictor] = pd.cut(df[predictor],10,labels=False)\n",
    "    if not predictor_mask:\n",
    "        predictor_mask = predictor\n",
    "    if not target_mask:\n",
    "        target_mask = target\n",
    "    if predictor_values_mask:\n",
    "        df = df.replace(predictor_values_mask)\n",
    "    if target_values_mask:\n",
    "        df = df.replace(target_values_mask)\n",
    "    plt.style.use(style)\n",
    "    plt.rc('font',size=fontsize)\n",
    "    df = df.dropna(subset=[predictor])\n",
    "    lengths = []\n",
    "    labels = np.append(df[predictor].unique(),target)\n",
    "    if(len(labels) > 25):\n",
    "        print('Error: Target variable ' + str(target) + ' contains more than 25 variants. Terminating procedure.')\n",
    "        return\n",
    "    plt.figure(figsize=(1.25*len(labels),6))\n",
    "    for j in df[target].unique():\n",
    "        for i in df[predictor].unique():\n",
    "            # For each variant in the target variable:\n",
    "            # For each variant in the predictor variable, save the number of times that the target variant and predictor variant appear together.\n",
    "            lengths.append(df.loc[df[predictor]==i].loc[df[target]==j][target].count()/df.loc[df[predictor]==i][target].count())\n",
    "        # At the end, append the number of the target variant divided by the total number of target instances.\n",
    "        # This gives us the native distribution of the target variable, which allows us to compare how different the various\n",
    "        # predictor categories are.\n",
    "        lengths.append(df.loc[df[target]==j][target].count()/df[target].count())\n",
    "    n = df[predictor].value_counts().values # Store the count of each prediction category, in case the user wants them displayed.\n",
    "    n = np.append(n,df[target].count())\n",
    "    for k in range(0,len(df[target].unique())):\n",
    "        if(k==0):\n",
    "            previousData=[0]*len(labels)\n",
    "        else:\n",
    "            previousData=[0]*len(labels)\n",
    "            for l in range(k,0,-1):\n",
    "                # This step is necessary in order to properly place the bar charts\n",
    "                # Essentially, we are printing the bar chart one layer at a time; bottom layer, next layer, and so on\n",
    "                # until we reach the top. In order to place the top layers correctly, we need to know where the last layer\n",
    "                # ended.\n",
    "                previousData=np.add(lengths[(l-1)*len(labels):l*len(labels)],previousData)\n",
    "        plt.bar(np.where(labels==target,target_mask,labels),lengths[k*len(labels):(k+1)*len(labels)],bottom=previousData,label=df[target].unique()[k])\n",
    "        if verbose:\n",
    "            labels = np.where(labels==target,target_mask,labels)\n",
    "            for m in range(0,len(labels)):\n",
    "                plt.text(labels[m],np.add(lengths[k*len(labels):(k+1)*len(labels)],previousData)[m],round(100*lengths[k*len(labels):(k+1)*len(labels)][m],2),ha=\"center\",va=\"top\")\n",
    "                if(k==len(df[target].unique())-1):\n",
    "                    plt.text(labels[m],np.add(lengths[k*len(labels):(k+1)*len(labels)],previousData)[m],\"N=\" + str(n[m]),ha=\"center\",va=\"bottom\")\n",
    "    plt.legend(bbox_to_anchor=(1.01,1.01),loc='upper left')\n",
    "    plt.xlabel(predictor_mask)\n",
    "    plt.ylabel('Distribution')\n",
    "    if verbose:\n",
    "        plt.title('Distribution of {} within {}'.format(target_mask,predictor_mask),pad=15.0)\n",
    "    else:\n",
    "        plt.title('Distribution of {} within {}'.format(target_mask,predictor_mask))\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.savefig('visualizations/exploration/perc{}by{}.png'.format(predictor,target),dpi=dpi,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}